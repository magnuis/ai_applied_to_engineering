{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Loading the data as a regular `pandas.DataFrame`. Then we proceed by converting the `time` feature to `pandas.DateTime`, before making it the index of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('weather_bcn.csv')\n",
    "\n",
    "# Extract only pres and time columns\n",
    "data = pd.DataFrame(data[['pres', 'time']], index=data.index, columns=['pres', 'time'])\n",
    "\n",
    "# Convert time column\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Make time the index\n",
    "data.set_index('time', inplace=True)\n",
    "assert type(data.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three null values out of 396 in the data set. We therefore use the Spline interpolation technique from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pres']= data['pres'].interpolate(option='spline')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test\n",
    "\n",
    "Help method for splitting the data set into train and test set, s.t. test contains data for the year 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    assert type(df.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "    \n",
    "    # Extract data for 2022\n",
    "    test = df[(df.index.year == 2022)]\n",
    "    train = df.drop(test.index)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract `pres`\n",
    "\n",
    "Making two dataframes (train and test) containing only the index and the `pres` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train = pd.DataFrame(data=scaler.fit_transform(train), index=train.index, columns=train.columns)\n",
    "test = pd.DataFrame(data=scaler.fit_transform(test), index=test.index, columns=test.columns)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12,6\n",
    "ax = train.plot();\n",
    "test.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity in the data\n",
    "\n",
    "#### Seasonal decomposition\n",
    "To get an initial idea of the stationarity of the data, we use `seasonal_decompose` from statsmodels to plot trend, seasonality and residuals :\n",
    "- **Trend:** the trend plot shows that the average temperature increases over time, thus indicating non-stationarity.\n",
    "- **Seasonality:** the data is clearly seasonal. This was to be expected, as the average atmosphric pressure (pres) is seasonal throughout the year.\n",
    "- **Residuals:** there appears to be no strong pattern in the residuals. \n",
    "\n",
    "Due to displayed trend and seasonality, the seasonal decomposition suggests that the data is non-stationary. \n",
    "\n",
    "#### ADF test\n",
    "We also did an Augmented Dickey-Fuller test on the data. Both of the observations below suggests stationarity in the data:\n",
    "- **ADF Test Statistc:** the test statistic is far more negative than the critical values at 1%, 5% and 10%. \n",
    "- **ADF p-value:** the p-value is very low.\n",
    "\n",
    "The results from the ADF test and the observations from the decomposition suggests that the data is stationary after accounting for trend and seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10,6\n",
    "result = seasonal_decompose(data)\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = adfuller(train)\n",
    "print('ADF test statistic:', adf[0])\n",
    "print('ADF p-values:', adf[1])\n",
    "print('ADF number of lags used:', adf[2])\n",
    "print('ADF number of observations:', adf[3])\n",
    "print('ADF critical values:', adf[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "\n",
    "### ARIMA Without Seasonality\n",
    "\n",
    "We start by applying `auto_arima` without seasonality (using default parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_unseasonal = auto_arima(train)\n",
    "arima_unseasonal.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal parameters found by `auto_arima` has `d=0`, supporting our observation on stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_unseasonal = arima_unseasonal.predict(n_periods= len(test))\n",
    "forecast_unseasonal = pd.DataFrame(forecast_unseasonal,index = test.index,columns=['ARIMA forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = train.plot()\n",
    "test.plot(ax=ax1)\n",
    "forecast_unseasonal.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ARIMA auto MSE:', round(mean_squared_error(test, forecast_unseasonal),2))\n",
    "print('ARIMA auto MAE:', round(mean_absolute_error(test, forecast_unseasonal),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA With Seasonality\n",
    "\n",
    "We proceed by training a new ARIMA model, this time with the annual seasonality shown by the decomposition (`m=12`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_seasonal = auto_arima(train, error_action='ignore', seasonal=True, m=12)\n",
    "arima_seasonal.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_seasonal = arima_seasonal.predict(n_periods=len(test))\n",
    "forecast_seasonal = pd.DataFrame(forecast_seasonal,index = test.index,columns=['ARIMA forecast (seasonal)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = test.plot()\n",
    "forecast_seasonal.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ARIMA seasonal MSE:', round(mean_squared_error(test, forecast_seasonal),2))\n",
    "print('ARIMA seasonal MAE:', round(mean_absolute_error(test, forecast_seasonal),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "\n",
    "ES_forecaster = ExponentialSmoothing(\n",
    "    endog=train['pres'],\n",
    "    seasonal='add',\n",
    "    seasonal_periods=12,\n",
    "    trend='add'\n",
    ").fit()\n",
    "\n",
    "\n",
    "# Forecast future values\n",
    "ES_forecast = ES_forecaster.forecast(12) \n",
    "\n",
    "ES_forecast = pd.DataFrame(ES_forecast, index = test.index,columns=['Exponential smoothing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ax1 = train.plot()\n",
    "ax1 = test.plot()\n",
    "ES_forecast.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exponential Smoothing MSE:', round(mean_squared_error(test, ES_forecast),2))\n",
    "print('Exponential Smoothing MAE:', round(mean_absolute_error(test, ES_forecast),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag features\n",
    "\n",
    "To enable the use of a regression model, we extract some features from the `pres` column:\n",
    "- **Quarter** - the quarter of the year.\n",
    "- **Month** - the month of the year.\n",
    "- **Last month** - the `pres` value of last month. Lag feature.\n",
    "- **Last year** - the `pres` value of last year. Lag feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_df = pd.DataFrame(data=train)\n",
    "\n",
    "def extract_quarter(month):\n",
    "    if month <= 3:\n",
    "        return 1\n",
    "    elif month <= 6:\n",
    "        return 2\n",
    "    elif month <= 9:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "# Add month feature\n",
    "lag_df['month'] = lag_df.index.month\n",
    "\n",
    "# Add quarterly feature\n",
    "lag_df['quarter'] = lag_df['month'].apply(extract_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To lag last year's value, we need to see if the index is continuous\n",
    "continuous_range = pd.date_range(start=lag_df.index.min(), end=lag_df.index.max(), freq='MS')\n",
    "assert (len(continuous_range) == len(lag_df.index) and all(continuous_range == lag_df.index))\n",
    "\n",
    "# Lag values\n",
    "lag_df['last_month'] = lag_df['pres'].shift(1)\n",
    "lag_df['last_2_month'] = lag_df['pres'].shift(2)\n",
    "lag_df['last_3_month'] = lag_df['pres'].shift(3)\n",
    "lag_df['last_year'] = lag_df['pres'].shift(12)\n",
    "\n",
    "# Because of the lag from the previous year, we need to drop the first 12 entries\n",
    "lag_df = lag_df.iloc[12:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "We opt for the `HistGradientBoostRegressor` from scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Split data into X and y\n",
    "y_train = lag_df['pres']\n",
    "X_train = lag_df.drop('pres', axis=1, inplace=False)\n",
    "\n",
    "# Train the model\n",
    "HGBR_model = HistGradientBoostingRegressor(random_state=42)\n",
    "HGBR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to prepare the forecasting data. As the next feature is dependent on the previous feature, and we will predict for the coming 12 months, we apply *recursive forecasting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DataFrame for the data to predict and for the predictions\n",
    "forecast_df = pd.DataFrame(index=[test.index[0]])\n",
    "predictions_df = pd.DataFrame(index=test.index)\n",
    "\n",
    "# Features in the prepared data\n",
    "features = X_train.columns.tolist()\n",
    "\n",
    "# Add month and quarter features\n",
    "forecast_df['month'] = forecast_df.index.month\n",
    "forecast_df['quarter'] = forecast_df['month'].apply(extract_quarter)\n",
    "\n",
    "# Add the last known data to the forecast_df \n",
    "forecast_df = forecast_df.assign(\n",
    "    last_month=lag_df.iloc[-1]['pres'],\n",
    "    last_2_month=lag_df.iloc[-2]['pres'],\n",
    "    last_3_month=lag_df.iloc[-3]['pres'],\n",
    "    last_year=lag_df.iloc[-13]['pres'],\n",
    ")\n",
    "\n",
    "# Apply the recursive forecasting\n",
    "for i in range(12):\n",
    "    # Current index\n",
    "    current_index = forecast_df.index[i]\n",
    "\n",
    "    # Predict next months pres\n",
    "    input_data = forecast_df.loc[[current_index], features]\n",
    "\n",
    "    # input_data = pd.DataFrame(index=[current_index], data=forecast_df.iloc[i], columns=features)\n",
    "    prediction = HGBR_model.predict(input_data)[0]\n",
    "\n",
    "    # Add the prediction\n",
    "    predictions_df.loc[predictions_df.index[i], 'pres'] = prediction\n",
    "\n",
    "    # Update the input features for the next forecast\n",
    "    if (i < 11): # Don't perform this step for the last month\n",
    "        \n",
    "        current_index = forecast_df.index[i]\n",
    "        next_index = predictions_df.index[i+1]\n",
    "\n",
    "        new_row = {\n",
    "            'month': next_index.month, \n",
    "            'quarter': extract_quarter(next_index.month),\n",
    "            'last_month': prediction,\n",
    "            'last_2_month': forecast_df.loc[current_index, 'last_month'],\n",
    "            'last_3_month': forecast_df.loc[current_index, 'last_2_month'],\n",
    "            'last_year': lag_df['pres'].iloc[-12 + (next_index.month - 1)]\n",
    "        }\n",
    "\n",
    "        forecast_df = pd.concat([forecast_df, pd.DataFrame(new_row, index=[next_index])], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax1 = train.plot()\n",
    "ax1 = test.plot()\n",
    "predictions_df.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HistGradientBoostRegressor MSE:', round(mean_squared_error(test, predictions_df.values),2))\n",
    "print('HistGradientBoostRegressor MAE:', round(mean_absolute_error(test, predictions_df.values),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
