{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Loading the data as a regular `pandas.DataFrame`. Then we proceed by converting the `time` feature to `pandas.DateTime`, before making it the index of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('weather_bcn.csv')\n",
    "\n",
    "# Extract only prcp and time columns\n",
    "data = pd.DataFrame(data[['prcp', 'time']], index=data.index, columns=['prcp', 'time'])\n",
    "\n",
    "# Convert time column\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Make time the index\n",
    "data.set_index('time', inplace=True)\n",
    "assert type(data.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three null values out of 396 in the data set. We therefore use the Spline interpolation technique from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prcp'] = data['prcp'].interpolate(option='spline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test\n",
    "\n",
    "Help method for splitting the data set into train and test set, s.t. test contains data for the year 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    assert type(df.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "    \n",
    "    # Extract data for 2022\n",
    "    test = df[(df.index.year == 2022)]\n",
    "    train = df.drop(test.index)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract `prcp`\n",
    "\n",
    "Making two dataframes (train and test) containing only the index and the `prcp` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12,6\n",
    "ax = train.plot();\n",
    "test.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity in the data\n",
    "\n",
    "#### Seasonal decomposition\n",
    "To get an initial idea of the stationarity of the data, we use `seasonal_decompose` from statsmodels to plot trend, seasonality and residuals :\n",
    "- **Trend:** the trend shows variations in the mean over time. This suggests an underlying non-stationarity in the data. \n",
    "- **Seasonality:** the data is clearly seasonal. This was to be expected, as the average precipitaion (prcp) is seasonal throughout the year.\n",
    "- **Residuals:** the residuals appear relatively constant around zero. This suggests that the trend and seasonality successfully captures the systematic variation in the data. \n",
    "\n",
    "Due to displayed trend and seasonality, the seasonal decomposition suggests that the data is non-stationary. \n",
    "\n",
    "#### ADF test\n",
    "We also did an Augmented Dickey-Fuller test on the data. Both of the observations below suggests stationarity in the data:\n",
    "- **ADF Test Statistc:** the test statistic is far more negative than the critical values at 1%, 5% and 10%. \n",
    "- **ADF p-value:** the p-value is effectively zero.\n",
    "\n",
    "The results from the ADF test and the observations from the decomposition suggests that the data is stationary after accounting for trend and seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10,6\n",
    "result = seasonal_decompose(data)\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = adfuller(train)\n",
    "print('ADF test statistic:', adf[0])\n",
    "print('ADF p-values:', adf[1])\n",
    "print('ADF number of lags used:', adf[2])\n",
    "print('ADF number of observations:', adf[3])\n",
    "print('ADF critical values:', adf[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "\n",
    "### ARIMA Without Seasonality\n",
    "\n",
    "We start by applying `auto_arima` without seasonality (using default parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_unseasonal = auto_arima(train)\n",
    "arima_unseasonal.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal parameters found by `auto_arima` has `d=0`, supporting our observation on stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_unseasonal = arima_unseasonal.predict(n_periods= len(test))\n",
    "forecast_unseasonal = pd.DataFrame(forecast_unseasonal,index = test.index,columns=['ARIMA forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = test.plot()\n",
    "forecast_unseasonal.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ARIMA auto MSE:', round(mean_squared_error(test, forecast_unseasonal),2))\n",
    "print('ARIMA auto MAE:', round(mean_absolute_error(test, forecast_unseasonal),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA With Seasonality\n",
    "\n",
    "We proceed by training a new ARIMA model, this time with the annual seasonality shown by the decomposition (`m=12`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_seasonal = auto_arima(train, error_action='ignore', seasonal=True, m=12)\n",
    "arima_seasonal.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_seasonal = arima_seasonal.predict(n_periods=len(test))\n",
    "forecast_seasonal = pd.DataFrame(forecast_seasonal,index = test.index,columns=['ARIMA forecast (seasonal)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = test.plot()\n",
    "forecast_seasonal.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ARIMA seasonal MSE:', round(mean_squared_error(test, forecast_seasonal),2))\n",
    "print('ARIMA seasonal MAE:', round(mean_absolute_error(test, forecast_seasonal),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "ES_forecaster = ExponentialSmoothing(\n",
    "    endog=train['prcp'],\n",
    "    seasonal='add',\n",
    "    seasonal_periods=12,\n",
    "    trend='add'\n",
    ").fit(\n",
    ")\n",
    "\n",
    "\n",
    "# Forecast future values\n",
    "ES_forecast = ES_forecaster.forecast(12) \n",
    "\n",
    "ES_forecast = pd.DataFrame(ES_forecast, index = test.index,columns=['Exponential smoothing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = test.plot()\n",
    "ES_forecast.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exponential Smoothing MSE:', round(mean_squared_error(test, ES_forecast),2))\n",
    "print('Exponential Smoothing MAE:', round(mean_absolute_error(test, ES_forecast),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag features\n",
    "\n",
    "To enable the use of a regression model, we extract some features from the `tavg` column:\n",
    "- **Quarter** - the quarter of the year.\n",
    "- **Month** - the month of the year.\n",
    "- **Last month** - the `tavg` value of last month. Lag feature.\n",
    "- **Last year** - the `tavg` value of last year. Lag feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quarter(month):\n",
    "    if month <= 3:\n",
    "        return 1\n",
    "    elif month <= 6:\n",
    "        return 2\n",
    "    elif month <= 9:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "\n",
    "def lag_features(df, feature, pres=pd.DataFrame()):\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    # Add quarterly feature\n",
    "    df['quarter'] = df['month'].apply(extract_quarter)\n",
    "\n",
    "    # To lag last year's value, we need to see if the index is continuous\n",
    "    continuous_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='MS')\n",
    "    assert (len(continuous_range) == len(df.index) and all(continuous_range == df.index))\n",
    "\n",
    "    # Lag values\n",
    "    df['last_month'] = df[feature].shift(1)\n",
    "    df['last_2_month'] = df[feature].shift(2)\n",
    "    df['last_3_month'] = df[feature].shift(3)\n",
    "    df['last_year'] = df[feature].shift(12)\n",
    "\n",
    "    # If pres is provided\n",
    "    if not pres.empty:\n",
    "        df['pres'] = pres\n",
    "\n",
    "    # Because of the lag from the previous year, we need to drop the first 12 entries\n",
    "    df = df.iloc[12:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dates, data, feature, model, pres=pd.DataFrame()):\n",
    "\n",
    "    data = data.copy()\n",
    "    # Make DataFrame for the data to predict and for the predictions\n",
    "    forecast_df = pd.DataFrame(index=[dates[0]])\n",
    "    predictions_df = pd.DataFrame(index=dates, columns=['prediction'])\n",
    "\n",
    "    # Features in the prepared data\n",
    "    features = data.columns.tolist()\n",
    "    features.remove(feature)\n",
    "\n",
    "    # Add month and quarter features\n",
    "    forecast_df['month'] = forecast_df.index.month\n",
    "    forecast_df['quarter'] = forecast_df['month'].apply(extract_quarter)\n",
    "\n",
    "    # Add the last known data to the forecast_df \n",
    "\n",
    "    if not pres.empty:\n",
    "        forecast_df = forecast_df.assign(\n",
    "            last_month=data.iloc[-1][feature],\n",
    "            last_2_month=data.iloc[-2][feature],\n",
    "            last_3_month=data.iloc[-3][feature],\n",
    "            last_year=data.iloc[-13][feature],\n",
    "            pres=pres[0]\n",
    "        )\n",
    "    else:\n",
    "        forecast_df = forecast_df.assign(\n",
    "            last_month=data.iloc[-1][feature],\n",
    "            last_2_month=data.iloc[-2][feature],\n",
    "            last_3_month=data.iloc[-3][feature],\n",
    "            last_year=data.iloc[-13][feature],\n",
    "        )\n",
    "        \n",
    "    # Apply the recursive forecasting\n",
    "    for i in range(12):\n",
    "        # Current index\n",
    "        current_index = forecast_df.index[i]\n",
    "\n",
    "        # Predict next months pres\n",
    "        input_data = forecast_df.loc[[current_index], features]\n",
    "\n",
    "        # input_data = pd.DataFrame(index=[current_index], data=forecast_df.iloc[i], columns=features)\n",
    "        prediction = model.predict(input_data)[0]\n",
    "\n",
    "        # Add the prediction\n",
    "        predictions_df.loc[predictions_df.index[i], 'prediction'] = prediction\n",
    "\n",
    "        # Update the input features for the next forecast\n",
    "        if (i < 11): # Don't perform this step for the last month\n",
    "            \n",
    "            current_index = forecast_df.index[i]\n",
    "            next_index = predictions_df.index[i+1]\n",
    "\n",
    "            new_row = {\n",
    "                'month': next_index.month, \n",
    "                'quarter': extract_quarter(next_index.month),\n",
    "                'last_month': prediction,\n",
    "                'last_2_month': forecast_df.loc[current_index, 'last_month'],\n",
    "                'last_3_month': forecast_df.loc[current_index, 'last_2_month'],\n",
    "                'last_year': data[feature].iloc[-12 + (next_index.month - 1)]\n",
    "            }\n",
    "\n",
    "            if not pres.empty:\n",
    "                new_row['pres'] = pres.iloc[i]\n",
    "\n",
    "            forecast_df = pd.concat([forecast_df, pd.DataFrame(new_row, index=[next_index])], ignore_index=False)\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_df = train.copy()\n",
    "lag_df = lag_features(lag_df, 'prcp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "We opt for the `HistGradientBoostRegressor` from scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Split data into X and y\n",
    "y_train = lag_df['prcp']\n",
    "X_train = lag_df.drop('prcp', axis=1, inplace=False)\n",
    "\n",
    "# Train the model\n",
    "HGBR_model = HistGradientBoostingRegressor(random_state=42)\n",
    "HGBR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to prepare the forecasting data. As the next feature is dependent on the previous feature, and we will predict for the coming 12 months, we apply *recursive forecasting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dates = test.index\n",
    "HGBR_predictions = predict(predict_dates, lag_df, 'prcp', HGBR_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = test.plot()\n",
    "HGBR_predictions.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HistGradientBoostRegressor MSE:', round(mean_squared_error(test, HGBR_predictions.values),2))\n",
    "print('HistGradientBoostRegressor MAE:', round(mean_absolute_error(test, HGBR_predictions.values),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag Features with pres\n",
    "\n",
    "Extract pres data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "pres_data = pd.read_csv('weather_bcn.csv')\n",
    "\n",
    "# Extract only pres and time columns\n",
    "pres_data = pd.DataFrame(pres_data[['pres', 'time']], index=pres_data.index, columns=['pres', 'time'])\n",
    "\n",
    "# Convert time column\n",
    "pres_data['time'] = pd.to_datetime(pres_data['time'])\n",
    "\n",
    "# Make time the index\n",
    "pres_data.set_index('time', inplace=True)\n",
    "assert type(pres_data.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "\n",
    "pres_data['pres'] = pres_data['pres'].interpolate(option='spline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `pres` column to the `prcp` predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new lagged df for prcp containing pres\n",
    "lag_df = train.copy()\n",
    "lag_df = lag_features(lag_df, 'prcp', pres_data['pres'])\n",
    "\n",
    "# Split data into X and y\n",
    "y_train = lag_df['prcp']\n",
    "X_train = lag_df.drop('prcp', axis=1, inplace=False)\n",
    "\n",
    "# Train the new model\n",
    "HGBR_model = HistGradientBoostingRegressor(random_state=42)\n",
    "HGBR_model.fit(X_train, y_train)\n",
    "\n",
    "# Make new predictions\n",
    "predict_dates = test.index\n",
    "HGBR_predictions = predict(predict_dates, lag_df, 'prcp', HGBR_model, lag_df['pres'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = test.plot()\n",
    "HGBR_predictions.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HistGradientBoostRegressor MSE:', round(mean_squared_error(test, HGBR_predictions.values),2))\n",
    "print('HistGradientBoostRegressor MAE:', round(mean_absolute_error(test, HGBR_predictions.values),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
