{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart disease data preparation\n",
    "First deliverable in the course *Artificial intelligence applied to engineering* at ETSEIB, UPC spring 2024. The team members contributing to the deliverable is \n",
    "- Lise Jakobsen\n",
    "- Julie Sørlie Lund\n",
    "- Magnus Ingnes Sagmo\n",
    "\n",
    "The dataset used in this deliverable can be retrieved from [Kaggle](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check the dimensions of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the heart dataset\n",
    "heart_data = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "# Check the dimensions of the dataset\n",
    "dataset_dimensions = heart_data.shape\n",
    "\n",
    "print(\"The dataset has {} rows and {} colums.\".format(dataset_dimensions[0],dataset_dimensions[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Understand the data structure\n",
    "*Peek at the first few rows to understand the data structure.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust pandas display settings\n",
    "pd.set_option('display.max_columns', 12)  # Ensure all columns are attempted to be displayed\n",
    "pd.set_option('display.width', 1000)  # Adjust the width \n",
    "\n",
    "\n",
    "# Display the first few rows of heart.csv\n",
    "print(heart_data.head())\n",
    "print('\\n')\n",
    "print(heart_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Examine the types of data present in each column \n",
    "*Examine the types of data present in each column (numerical, categorical, datetime, ...). Verify that the data types assigned to each column align with the actual nature of the data. Convert data types if necessary.*\n",
    "\n",
    "In the original dataset, the columns `Sex`, `ChestPainType`, `RestingECG`, `ExerciseAngina` and `ST_Slope` are of the `pandas.object` data type. All of the values are however of a categorical type, and were consequently changed to the `pandas.category` data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display data types \n",
    "def display_dtypes(dataframe):\n",
    "    # Create a DataFrame from the dtypes\n",
    "    dtypes_df = pd.DataFrame(dataframe.dtypes, columns=['Data Type'])\n",
    "    # Reset index to get the column names as a separate column\n",
    "    dtypes_df.reset_index(inplace=True)\n",
    "    # Rename columns \n",
    "    dtypes_df.columns = ['Column Name', 'Data Type']\n",
    "    # Display the DataFrame\n",
    "    display(dtypes_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original data types\n",
    "print(\"Original Data Types:\")\n",
    "display_dtypes(heart_data)\n",
    "\n",
    "# Convert categorical variables to 'category' data type\n",
    "categorical_columns = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope', 'FastingBS']\n",
    "# categorical_columns = heart_data.select_dtypes(include='object').columns.to_list()\n",
    "heart_data[categorical_columns] = heart_data[categorical_columns].astype('category')\n",
    "\n",
    "# Display data types after conversion for comparison\n",
    "print(\"\\nData Types after Conversion:\")\n",
    "display_dtypes(heart_data)\n",
    "heart_data = heart_data\n",
    "print(heart_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Filter the data \n",
    "*Filter the data by removing variables that are not relevant for the analysis.*\n",
    "\n",
    "Given the context of predicting heart failure, all of the 12 variables have relevant associations with cardiovascular health and could potentially provide valuable insights when building a predictive model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Univariate analysis\n",
    "*Summarize statistics for numerical variables and frequency distribution for categorical ones. Create visualizations (histograms, box plots, bar plots, etc).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Summary statistics for numerical variables\n",
    "print(\"Summary Statistics for Numerical Variables:\")\n",
    "print(heart_data.describe())\n",
    "\n",
    "# Histograms for numerical variables\n",
    "numerical_columns = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "for col in numerical_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(heart_data[col], kde=True, bins=30)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Frequency distribution and bar plots for categorical variables\n",
    "categorical_columns = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "for col in categorical_columns:\n",
    "    print(f\"Frequency distribution for {col}:\")\n",
    "    print(heart_data[col].value_counts())\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=col, data=heart_data)\n",
    "    plt.title(f'Bar Plot of {col}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Outliers\n",
    "*Identify outliers and decide whether to remove, transform, or keep them.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQR_method(dataframe, column, lower_quantile=0.25, upper_quantile=0.75):\n",
    "    ''''Calculate outliers for a given column using the IQR method\n",
    "\n",
    "    The IQR is the difference between the 75th percentile (Q3) and the 25th percentile (Q1) of the data.\n",
    "    Outliers are typically considered data points that fall below (Q1- 1,5*IQR) or above (Q3 + 1,5*IQR).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : pandas.DataFrame\n",
    "        The data to locate outliers in \n",
    "    column : str\n",
    "        Name of column to locate outliers in\n",
    "    lower_quantile : float\n",
    "        Quantile to represent the lower bound (default is 0.25 for Q1)\n",
    "    upper_quantile : float\n",
    "        Quantile to represent the upper bound (default is 0.75 for Q3)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Dataframe without entries containing outliers for the provided column\n",
    "    '''\n",
    "\n",
    "    Q1 = dataframe[column].quantile(lower_quantile)\n",
    "    Q3 = dataframe[column].quantile(upper_quantile)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Selecting rows that are not considered outliers\n",
    "    return dataframe[(dataframe[column] >= lower_bound) & (dataframe[column] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by removing the zero values for the columns desrcribed below.\n",
    "\n",
    "##### RestingBP\n",
    "\n",
    "- Normal blood pressure for adults ranges from 90/60 mm KG to 120/80 mm Hg. \n",
    "- A resting blood pressure of zero is impossible. The occurences of `RestingBP=0` in the dataset are therefore most likely due to an error. As it is difficult to infer an approximation to the blood pressure, and it is an important risk factor for ehart disease, we have decided to remove the zero blood pressure values. \n",
    "\n",
    "##### Cholesterol\n",
    "- High cholesterol levels are clinically relevant and can indicate a significant risk for cardiovascular diseases. \n",
    "- The instances where cholesterol is recorded as 0 are clearly errors or missing data, as it's physiologically impossible for someone to have no cholesterol. All records where `Cholesterol=0` were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_len = heart_data.shape[0]\n",
    "heart_data = heart_data[(heart_data['RestingBP'] > 0)]\n",
    "intermediate_len = heart_data.shape[0]\n",
    "resting_bp_removed = old_len - intermediate_len\n",
    "\n",
    "heart_data = heart_data[(heart_data['Cholesterol'] > 0)]\n",
    "new_len = heart_data.shape[0]\n",
    "cholesterol_removed = intermediate_len - new_len\n",
    "\n",
    "print(f'Removed {resting_bp_removed} rows for RestingBP and {cholesterol_removed} rows for Cholesterol.')\n",
    "print(f'The new dataframe has {new_len} entries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_outliers(dataframe, variables):\n",
    "    '''Display outliers for dataframe using IQR method\n",
    "\n",
    "    Apply the IQR method to given dataframe for each of the given variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : pandas.DataFrame\n",
    "        The data to locate outliers in \n",
    "    column : list of str\n",
    "        List of column names for numerical variables to locate outliers in\n",
    "    '''\n",
    "    for variable in variables:\n",
    "        outliers_df = IQR_method(dataframe, variable, 0.25, 0.75)\n",
    "        print(f\"Number of outliers in {variable}: {len(outliers_df)}\")\n",
    "        if len(outliers_df) > 0:\n",
    "            display(outliers_df[[variable]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceed by locating and removing outliers for the attributes below.\n",
    "\n",
    "#### RestingBP\n",
    "\n",
    "- High blood pressure is a critical risk factor for heart disease. We will therefore only look for lower quantile outliers for `RestingB`.\n",
    "\n",
    "#### Cholesterol\n",
    "- High cholesterol levels are clinically relevant and can indicate a significant risk for cardiovascular diseases. We will therefore only look for lower quantile outliers for `RestingB`.\n",
    "\n",
    "#### MaxHR  \n",
    "\n",
    "\n",
    "#### Oldpeak \n",
    "- *Oldpeak* refers to the ST depression induced by exercise relative to rest, measured in millimeters (mm) on an electrocardiogram (ECG). ST depression is a finding on an ECG that can indicate myocardial ischemia, a condition where part of the heart does not receive enough oxygen, often due to blockages in the coronary arteries. In the context of a stress test, an increase in oldpeak value (more negative or more pronounced depression) can suggest a higher likelihood of coronary artery disease.\n",
    "- ST Elevation: An ST amplitude of ≥0.1 mV, ≥0.15 mV, and ≥0.2 mV is considered significant for ST elevation. ST elevation can indicate acute myocardial infarction (heart attack) and other conditions that lead to an elevated risk of heart disease. High positive Oldpeak values (e.g., 4.0, 5.6, 6.2) are well above the ≥0.2 mV elevation significance threshold, indicating substantial ST segment deviations. These are critical for identifying potential heart disease risk and should be retained for their clinical significance.\n",
    "- ST Depression: For ST depression, thresholds of ≤–0.05 mV or ≤–0.1 mV are used to denote clinical significance. ST depression is indicative of myocardial ischemia, a condition where the heart muscle doesn't receive enough oxygen, often due to narrowed or blocked coronary arteries. With ST depression being clinically significant at values of ≤–0.05 mV or ≤–0.1 mV, a negative Oldpeak value reflects ST depression and is thus clinically relevant. This value suggests myocardial ischemia and should be included in analyses concerning heart disease risk, assuming the negative sign indicates depression below the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RestingBP\n",
    "new_df = IQR_method(heart_data, 'RestingBP', lower_quantile=0.25)\n",
    "intermediate_len = new_df.shape[0]\n",
    "restingbp_removed = heart_data.shape[0] - intermediate_len\n",
    "\n",
    "# Cholesterol\n",
    "new_df = IQR_method(new_df, 'Cholesterol', lower_quantile=0.25)\n",
    "cholesterol_removed = intermediate_len - new_df.shape[0]\n",
    "intermediate_len = new_df.shape[0]\n",
    "\n",
    "# MaxHR\n",
    "new_df = IQR_method(new_df, 'MaxHR', lower_quantile=0.25, upper_quantile=0.75)\n",
    "maxhr_removed = intermediate_len - new_df.shape[0]\n",
    "intermediate_len = new_df.shape[0]\n",
    "\n",
    "# Oldpeak\n",
    "new_df = IQR_method(new_df, 'Oldpeak', lower_quantile=0.25, upper_quantile=0.75)\n",
    "oldpeak_removed = intermediate_len - new_df.shape[0]\n",
    "intermediate_len = new_df.shape[0]\n",
    "\n",
    "heart_data = new_df\n",
    "\n",
    "print(f\"Removed {resting_bp_removed} values for 'RestingBP', {cholesterol_removed} values for 'Cholesterol', {maxhr_removed} values for 'MaxHR' and {oldpeak_removed} values for 'Oldpeak'\")\n",
    "print(f\"The resulting dataframe has {heart_data.shape[0]} entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create new features \n",
    "*Create new features from existing ones if necessary (e.g., extracting date components, ratios between variables, etc.).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resting blood pressure varies with sex and age. We have categorised in `low`, `normal` and `high` blood pressure according to a table from [Heart research institute](https://www.hri.org.au/health/learn/risk-factors/what-is-normal-blood-pressure-by-age):\n",
    "\n",
    "| Age Range   | F             | M             |\n",
    "|-------------|---------------|---------------|\n",
    "| 18–39 years | 110/68 mm Hg  | 119/70 mm Hg  |\n",
    "| 40–59 years | 122/74 mm Hg  | 124/77 mm Hg  |\n",
    "| 60+ years   | 139/68 mm Hg  | 133/69 mm Hg  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bp_category(row):\n",
    "    age = row['Age']\n",
    "    sex = row['Sex']\n",
    "    bp = row['RestingBP']\n",
    "\n",
    "    normal_bp_values = {\n",
    "        'young': {'F': 110, 'M': 119},\n",
    "        'middle': {'F': 122, 'M': 124},\n",
    "        'old': {'F': 139, 'M': 133}\n",
    "    }\n",
    "\n",
    "    if age <= 39:\n",
    "        age_group = 'young'\n",
    "    elif age <= 59:\n",
    "        age_group = \"middle\"\n",
    "    else:\n",
    "        age_group = \"old\"\n",
    "\n",
    "    # Retrieve the normal BP for the age and sex\n",
    "    if sex == 'M' or sex == '1' or sex == 'm':\n",
    "        sex = 'M'\n",
    "    else: sex = 'F'\n",
    "\n",
    "    normal_bp = normal_bp_values[age_group][sex]\n",
    "\n",
    "    if bp <= (normal_bp - 3):\n",
    "        return 'low'\n",
    "    elif normal_bp - 3 < bp < normal_bp + 3:\n",
    "        return 'normal'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "\n",
    "heart_data['BloodPressure'] = heart_data.apply(get_bp_category, axis=1)\n",
    "\n",
    "# Make new feature categorical\n",
    "heart_data[['BloodPressure']] = heart_data[['BloodPressure']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate categorical columns\n",
    "categorical_columns = heart_data.select_dtypes(include='category').columns.to_list()\n",
    "\n",
    "# Create new columns with encoded values\n",
    "for column in categorical_columns:\n",
    "    heart_data[column] = heart_data[column].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Feature importance\n",
    "*Identify variables that provide little to no information and remove them.*\n",
    "\n",
    "To look for feature importance of each individual feature, we use the `sklearn.RandomForestClassifier` as it has a built-in `feature_importance_` parameter. \n",
    "\n",
    "The code below is inspired by dialogue with ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Copy data\n",
    "X = heart_data.copy()\n",
    "y = X['HeartDisease']\n",
    "X = X.drop('HeartDisease', axis=1)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "df = pd.DataFrame({'Feature': X_train.columns.tolist(), 'Importance': model.feature_importances_})\n",
    "df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the code above, we see that `Sex`, `RestingECG` and `FastingBS` have seemingly lower importance than the other features. We will therefore remove these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = heart_data.drop(columns=['Sex', 'RestingECG', 'FastingBS', 'BloodPressure'], axis=1)\n",
    "print(heart_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Scale numerical features \n",
    "*Scale numerical features to a similar range in order to improve model performance on some models.*\n",
    "\n",
    "Applying [min-max scaling](https://towardsdatascience.com/everything-you-need-to-know-about-min-max-normalization-in-python-b79592732b79) to the originally numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the desired values\n",
    "df = pd.DataFrame(heart_data[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']])\n",
    "\n",
    "print(heart_data.columns)\n",
    "# Min-max scaling\n",
    "df_scaled = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Divide the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
